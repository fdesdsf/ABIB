{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdc0ubGvcNTI8uNs0N3hpy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fdesdsf/ABIB/blob/main/text_analytics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIbPi8e2qWQH",
        "outputId": "c081a412-9eca-4e1b-9cab-57249172fb91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = '/content/drive/MyDrive/Classroom/flipkart_product.csv'\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv(file_path, encoding='latin-1')\n",
        "    print(\"Loaded with latin-1 encoding:\")\n",
        "    print(df.head())\n",
        "except UnicodeDecodeError:\n",
        "    try:\n",
        "        df = pd.read_csv(file_path, encoding='cp1252')\n",
        "        print(\"Loaded with cp1252 encoding:\")\n",
        "        print(df.head())\n",
        "    except UnicodeDecodeError:\n",
        "        print(\"Could not decode with latin-1 or cp1252. Try other encodings.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKc4FERtralr",
        "outputId": "47aad108-6b77-448f-e4ea-169291940f31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded with latin-1 encoding:\n",
            "                                         ProductName     Price Rate  \\\n",
            "0  Candes 12 L Room/Personal Air Cooler?ÿ?ÿ(White...  ??3,999    5   \n",
            "1  Candes 12 L Room/Personal Air Cooler?ÿ?ÿ(White...  ??3,999    5   \n",
            "2  Candes 12 L Room/Personal Air Cooler?ÿ?ÿ(White...  ??3,999    3   \n",
            "3  Candes 12 L Room/Personal Air Cooler?ÿ?ÿ(White...  ??3,999    1   \n",
            "4  Candes 12 L Room/Personal Air Cooler?ÿ?ÿ(White...  ??3,999    3   \n",
            "\n",
            "            Review                                            Summary  \n",
            "0           Super!  Great cooler.. excellent air flow and for this...  \n",
            "1          Awesome             Best budget 2 fit cooler. Nice cooling  \n",
            "2             Fair  The quality is good but the power of air is de...  \n",
            "3  Useless product                 Very bad product it's a only a fan  \n",
            "4             Fair                                      Ok ok product  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get basic information about the DataFrame\n",
        "print(\"DataFrame Info:\")\n",
        "df.info()\n",
        "\n",
        "# Print a sample of non-head rows to see the content\n",
        "print(\"\\nSample of Data:\")\n",
        "print(df.sample(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FD9YF0ThzUIP",
        "outputId": "e8c732d1-7a18-4f64-d1ad-832557af051c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 189874 entries, 0 to 189873\n",
            "Data columns (total 5 columns):\n",
            " #   Column       Non-Null Count   Dtype \n",
            "---  ------       --------------   ----- \n",
            " 0   ProductName  189874 non-null  object\n",
            " 1   Price        189873 non-null  object\n",
            " 2   Rate         189873 non-null  object\n",
            " 3   Review       189870 non-null  object\n",
            " 4   Summary      189860 non-null  object\n",
            "dtypes: object(5)\n",
            "memory usage: 7.2+ MB\n",
            "\n",
            "Sample of Data:\n",
            "                                              ProductName      Price Rate  \\\n",
            "80562   LUMINOUS ZELIO+ 1100/12V (E-comm) Pure Sine Wa...   ??7,299    3   \n",
            "96779   APPLE 2020 Macbook Air M1 - (8 GB/256 GB SSD/M...  â¹86,990    5   \n",
            "133508         POCO C31 (Royal Blue, 64 GB)?ÿ?ÿ(4 GB RAM)   ??7,499    5   \n",
            "60833   Google Nest Hub (2nd gen), Display with Google...   ??6,999    5   \n",
            "32184   Midea TORRINO,WQP12-5201F Free Standing 13 Pla...  ??25,990    4   \n",
            "167492  cello Pack of 18 Opalware Cello Dazzle Lush Fi...   â¹1,299    5   \n",
            "168089  cello Pack of 18 Opalware Cello Dazzle Lush Fi...   â¹1,299    5   \n",
            "164353  cello Pack of 18 Opalware Cello Dazzle Lush Fi...   â¹1,299    5   \n",
            "122139         Men Graphic Print Round Neck Black T-Shirt     ??269    4   \n",
            "9673    RIAN Animal Single Mink Blanket for  Mild Wint...     â¹599    4   \n",
            "\n",
            "                                     Review  \\\n",
            "80562                                  Good   \n",
            "96779                    Highly recommended   \n",
            "133508                              Awesome   \n",
            "60833   A must have gadget for a smart home   \n",
            "32184                            Delightful   \n",
            "167492                            Fabulous!   \n",
            "168089                       Simply awesome   \n",
            "164353                            Fabulous!   \n",
            "122139                                  Nan   \n",
            "9673                           Nice product   \n",
            "\n",
            "                                                  Summary  \n",
            "80562   Avarage product. But flip cart delivery servic...  \n",
            "96779   Awesome performance and build quality and my c...  \n",
            "133508                                               Nice  \n",
            "60833   It serves my basic needs to set up a smart hom...  \n",
            "32184   Really happy with the dishwasher.Dishes comes ...  \n",
            "167492  The steal deal...18 pieces of opalware at a ve...  \n",
            "168089                                               Good  \n",
            "164353                                          very good  \n",
            "122139                                               Nice  \n",
            "9673                                Love with the blanket  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values in the 'Review' column\n",
        "print(\"Missing values in 'Review' before handling:\")\n",
        "print(df['Review'].isnull().sum())\n",
        "\n",
        "# Drop rows with missing values in the 'Review' column\n",
        "df.dropna(subset=['Review'], inplace=True)\n",
        "\n",
        "# Verify missing values after handling\n",
        "print(\"\\nMissing values in 'Review' after handling:\")\n",
        "print(df['Review'].isnull().sum())\n",
        "\n",
        "# Convert 'Review' text to lowercase\n",
        "df['Review'] = df['Review'].str.lower()\n",
        "\n",
        "# Display the first few rows of the cleaned 'Review' column\n",
        "print(\"\\nFirst few cleaned reviews:\")\n",
        "print(df['Review'].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpwa_4gR1VL9",
        "outputId": "d7e6d958-b5bd-4ad4-8b2e-8547fb9a2f77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in 'Review' before handling:\n",
            "4\n",
            "\n",
            "Missing values in 'Review' after handling:\n",
            "0\n",
            "\n",
            "First few cleaned reviews:\n",
            "0             super!\n",
            "1            awesome\n",
            "2               fair\n",
            "3    useless product\n",
            "4               fair\n",
            "Name: Review, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "# Download VADER lexicon if you haven't already\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "# Initialize the VADER sentiment analyzer\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Function to get the negative sentiment score\n",
        "def get_negative_sentiment_score(text):\n",
        "    vs = analyzer.polarity_scores(text)\n",
        "    return vs['neg']\n",
        "\n",
        "# Apply the function to the 'Review' column to get the negative sentiment score\n",
        "df['negative_sentiment_score'] = df['Review'].apply(get_negative_sentiment_score)\n",
        "\n",
        "# Display the first few rows with the negative sentiment scores\n",
        "print(df[['Review', 'negative_sentiment_score']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0bGCrvS1dTi",
        "outputId": "7e4e18f3-c11b-4f18-d486-7728b95ee2d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            Review  negative_sentiment_score\n",
            "0           super!                     0.000\n",
            "1          awesome                     0.000\n",
            "2             fair                     0.000\n",
            "3  useless product                     0.737\n",
            "4             fair                     0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a threshold for considering a review as highly negative\n",
        "negative_threshold = 0.5\n",
        "\n",
        "# Filter the DataFrame to get reviews with a negative sentiment score above the threshold\n",
        "highly_negative_reviews_df = df[df['negative_sentiment_score'] > negative_threshold]\n",
        "\n",
        "# Display the number of highly negative reviews\n",
        "print(f\"Number of highly negative reviews (threshold > {negative_threshold}): {len(highly_negative_reviews_df)}\")\n",
        "\n",
        "# Display a sample of the highly negative reviews and their scores\n",
        "print(\"\\nSample of highly negative reviews:\")\n",
        "print(highly_negative_reviews_df[['Review', 'negative_sentiment_score']].head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQD_nCKz2tAU",
        "outputId": "67538456-cab1-4d8c-8ee4-3ad1387efc0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of highly negative reviews (threshold > 0.5): 13442\n",
            "\n",
            "Sample of highly negative reviews:\n",
            "                     Review  negative_sentiment_score\n",
            "3           useless product                     0.737\n",
            "48          waste of money!                     0.607\n",
            "59                worthless                     1.000\n",
            "67   worst experience ever!                     0.687\n",
            "73          useless product                     0.737\n",
            "80                 not good                     0.706\n",
            "84    slightly disappointed                     0.737\n",
            "87                 horrible                     1.000\n",
            "99                very poor                     0.772\n",
            "104         useless product                     0.737\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Keywords related to price\n",
        "price_keywords = ['price', 'cost', 'expensive', 'overpriced', 'cheap (negative context)', 'money waste']\n",
        "\n",
        "# Keywords related to lack of features\n",
        "feature_keywords = ['feature missing', 'no feature', 'lacks', 'not have', 'without', 'basic']\n",
        "\n",
        "# Keywords related to poor service\n",
        "service_keywords = ['service bad', 'poor service', 'customer care worst', 'support bad', 'delivery late', 'damaged', 'broken']\n",
        "\n",
        "# Function to check if any of the keywords are present in the review\n",
        "def contains_keyword(text, keywords):\n",
        "    if isinstance(text, str):\n",
        "        for keyword in keywords:\n",
        "            if keyword in text:\n",
        "                return True\n",
        "    return False\n",
        "\n",
        "# Filter for negative reviews mentioning price-related keywords\n",
        "negative_price_reviews_df = highly_negative_reviews_df[highly_negative_reviews_df['Review'].apply(lambda x: contains_keyword(x, price_keywords))]\n",
        "print(f\"\\nNumber of highly negative reviews mentioning price: {len(negative_price_reviews_df)}\")\n",
        "print(negative_price_reviews_df[['Review', 'negative_sentiment_score']].head())\n",
        "\n",
        "# Filter for negative reviews mentioning feature-related keywords\n",
        "negative_feature_reviews_df = highly_negative_reviews_df[highly_negative_reviews_df['Review'].apply(lambda x: contains_keyword(x, feature_keywords))]\n",
        "print(f\"\\nNumber of highly negative reviews mentioning lack of features: {len(negative_feature_reviews_df)}\")\n",
        "print(negative_feature_reviews_df[['Review', 'negative_sentiment_score']].head())\n",
        "\n",
        "# Filter for negative reviews mentioning service-related keywords\n",
        "negative_service_reviews_df = highly_negative_reviews_df[highly_negative_reviews_df['Review'].apply(lambda x: contains_keyword(x, service_keywords))]\n",
        "print(f\"\\nNumber of highly negative reviews mentioning poor service: {len(negative_service_reviews_df)}\")\n",
        "print(negative_service_reviews_df[['Review', 'negative_sentiment_score']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwnJF3Hx21j4",
        "outputId": "f7da11b1-f51a-446b-893c-d5bbdc628972"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of highly negative reviews mentioning price: 0\n",
            "Empty DataFrame\n",
            "Columns: [Review, negative_sentiment_score]\n",
            "Index: []\n",
            "\n",
            "Number of highly negative reviews mentioning lack of features: 1\n",
            "                                         Review  negative_sentiment_score\n",
            "181496  worst and useless without installation                      0.697\n",
            "\n",
            "Number of highly negative reviews mentioning poor service: 4\n",
            "                         Review  negative_sentiment_score\n",
            "1015                    damaged                     1.000\n",
            "17775           damaged product                     0.744\n",
            "53841           damaged product                     0.744\n",
            "128449  came with broken cover.                     0.508\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import spacy\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Download stopwords if you haven't already\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load the English language model for spaCy\n",
        "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\"]) # Disable Named Entity Recognition for speed\n",
        "\n",
        "# Get the set of English stop words\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "def preprocess_text(text):\n",
        "    if isinstance(text, str):\n",
        "        # Tokenize the text using spaCy\n",
        "        doc = nlp(text)\n",
        "        # Lemmatize and remove stop words and punctuation\n",
        "        tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct and not token.is_space]\n",
        "        return \" \".join(tokens)\n",
        "    return \"\"\n",
        "\n",
        "# Apply the preprocessing function to the 'Review' column\n",
        "df['processed_review'] = df['Review'].apply(preprocess_text)\n",
        "\n",
        "# Remove rows where the processed review is empty\n",
        "df.dropna(subset=['processed_review'], inplace=True)\n",
        "df = df[df['processed_review'].str.len() > 0]\n",
        "\n",
        "# Display the first few processed reviews\n",
        "print(df[['Review', 'processed_review']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdbVzItM8xgf",
        "outputId": "3793629d-cb13-497c-ad9a-4eb93c63f2ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            Review processed_review\n",
            "0           super!            super\n",
            "1          awesome          awesome\n",
            "2             fair             fair\n",
            "3  useless product  useless product\n",
            "4             fair             fair\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Initialize the TF-IDF vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
        "\n",
        "# Fit and transform the processed reviews\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(df['processed_review'])\n",
        "\n",
        "# Get the feature names (words)\n",
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "# Print the shape of the TF-IDF matrix and the number of features\n",
        "print(f\"Shape of TF-IDF matrix: {tfidf_matrix.shape}\")\n",
        "print(f\"Number of unique features (words): {len(feature_names)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwsaUkTMCeZ-",
        "outputId": "5cc56589-9591-4c01-dca3-1f67adba378c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of TF-IDF matrix: (189857, 415)\n",
            "Number of unique features (words): 415\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "# Define the number of topics you want to extract\n",
        "num_topics = 10  # You can experiment with different numbers of topics\n",
        "\n",
        "# Initialize the LDA model\n",
        "lda_model = LatentDirichletAllocation(n_components=num_topics, random_state=42, n_jobs=-1)\n",
        "\n",
        "# Fit the LDA model to the TF-IDF matrix\n",
        "lda_model.fit(tfidf_matrix)\n",
        "\n",
        "# Function to display the top words for each topic\n",
        "def display_topics(model, feature_names, num_top_words=10):\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        print(f\"Topic {topic_idx}:\")\n",
        "        top_words_indices = topic.argsort()[:-num_top_words - 1:-1]\n",
        "        top_words = [feature_names[i] for i in top_words_indices]\n",
        "        print(\" \".join(top_words))\n",
        "\n",
        "# Display the discovered topics and their top words\n",
        "print(\"\\nDiscovered Topics:\")\n",
        "display_topics(lda_model, feature_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5psqRHVCn2v",
        "outputId": "97e759bf-08b5-4f84-f838-6cd1f06c62e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Discovered Topics:\n",
            "Topic 0:\n",
            "nice market okay product hate disappointed slightly performance month family\n",
            "Topic 1:\n",
            "simply awesome job waste bad money poor unsatisfactory experience quality\n",
            "Topic 2:\n",
            "awesome excellent recommend highly moderate meet expectation price range microwave\n",
            "Topic 3:\n",
            "good wow choice pretty quality product disappoint utterly work ball\n",
            "Topic 4:\n",
            "delightful worthless horrible juicer tv review need kitchen overprice laptop\n",
            "Topic 5:\n",
            "terrific wonderful product classy perfect purchase mixer grinder cool like\n",
            "Topic 6:\n",
            "product great penny worth decent terrible rubbish absolute expect star\n",
            "Topic 7:\n",
            "money blow mind purchase value worth fair superb budget inverter\n",
            "Topic 8:\n",
            "nan useless way product love fantastic perform slot honest face\n",
            "Topic 9:\n",
            "brilliant buy fabulous super camera inalsa box hand table link\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Get the topic distribution for each document\n",
        "topic_distributions = lda_model.transform(tfidf_matrix)\n",
        "\n",
        "# Function to get the dominant topic for each document\n",
        "def get_dominant_topic(topic_distribution):\n",
        "    return np.argmax(topic_distribution)\n",
        "\n",
        "# Apply the function to get the dominant topic for each review\n",
        "df['dominant_topic'] = np.apply_along_axis(get_dominant_topic, 1, topic_distributions)\n",
        "\n",
        "# Filter the DataFrame for reviews primarily associated with Topic 2 (index 2)\n",
        "topic_2_reviews_df = df[df['dominant_topic'] == 2]\n",
        "print(\"\\nSample Reviews Primarily Associated with Topic 2 (Price/Alternatives):\")\n",
        "print(topic_2_reviews_df['Review'].head(10).values)\n",
        "\n",
        "# Filter the DataFrame for reviews primarily associated with Topic 1 (index 1)\n",
        "topic_1_reviews_df = df[df['dominant_topic'] == 1]\n",
        "print(\"\\nSample Reviews Primarily Associated with Topic 1 (Pain Points/Quality):\")\n",
        "print(topic_1_reviews_df['Review'].head(10).values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QT8Uh3LBE_39",
        "outputId": "e6ca4dde-aa4a-4226-ae0f-864d65dc6ba0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample Reviews Primarily Associated with Topic 2 (Price/Alternatives):\n",
            "['awesome' 'awesome' 'highly recommended' 'highly recommended' 'awesome'\n",
            " 'awesome' 'excellent' 'awesome' 'excellent' 'awesome']\n",
            "\n",
            "Sample Reviews Primarily Associated with Topic 1 (Pain Points/Quality):\n",
            "['unsatisfactory' 'simply awesome' 'waste of money!' 'does the job'\n",
            " 'worst experience ever!' 'simply awesome' 'simply awesome'\n",
            " 'simply awesome' 'very poor' 'simply awesome']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-0686c74623a1>:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['dominant_topic'] = np.apply_along_axis(get_dominant_topic, 1, topic_distributions)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!find /content/drive -name 'flipkart_product.csv'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHbIkhSAsP3n",
        "outputId": "d678bea0-ad7b-425d-dcba-ebf1a4f14a27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Classroom/flipkart_product.csv\n"
          ]
        }
      ]
    }
  ]
}